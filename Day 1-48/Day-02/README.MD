# ğŸ§  Vector Concepts for AI/ML

## ğŸ“Œ What is a Vector?
- A **vector** is an ordered array of numbers.
- Represents **magnitude and direction** in space.
- Used to store features (data points) in AI/ML.
- **Example**: `[3, 4]` or `(height, weight)`

---

## ğŸ”¢ Vector Space
- A **vector space** is a collection of vectors that can be added together and multiplied (scaled) by numbers.
- Follows rules like associativity, commutativity, and identity.

---

## ğŸ“ Vector Norms (Length of a Vector)
Used to measure the **size** or **distance** of a vector.

### â¤ L1 Norm (Manhattan Distance)
- Formula: `|xâ‚| + |xâ‚‚| + ... + |xâ‚™|`
- Path-like movement (up/down, left/right).
- Example: `||[3, 4]||â‚ = 3 + 4 = 7`
- **Used in:** Sparse data models, Lasso regularization.

### â¤ L2 Norm (Euclidean Distance)
- Formula: `sqrt(xâ‚Â² + xâ‚‚Â² + ... + xâ‚™Â²)`
- Straight-line distance.
- Example: `||[3, 4]||â‚‚ = sqrt(9 + 16) = 5`
- **Used in:** Most ML models, Ridge regularization.

### â¤ Lâˆ Norm (Chebyshev Distance)
- Formula: `max(|xâ‚|, |xâ‚‚|, ..., |xâ‚™|)`
- Focuses on the largest coordinate.
- Example: `||[3, 4]||âˆ = 4`
- **Used in:** Robust control, some anomaly detection.

---

## ğŸ¯ Why Use Norms?
- To measure **how far apart** data points are.
- To compare vectors regardless of direction.
- Important in **KNN**, **loss functions**, **regularization**, and **similarity search**.

---

## ğŸ”„ Normalization
- Converts vectors to **unit length** (norm = 1).
- Formula: `v_normalized = v / ||v||`
- Used to remove scale effects in models.

---

## ğŸ¤ Cosine Similarity
- Measures angle (not distance) between vectors.
- Formula: `cos(Î¸) = (A Â· B) / (||A|| ||B||)`
- Value ranges: `-1` (opposite) to `1` (same direction)
- Used in **text similarity**, **recommendation systems**.

---

## ğŸ“‰ Regularization
Helps prevent **overfitting** in models:

- **L1 Regularization (Lasso)**: Adds `Î» * ||w||â‚` to loss.
  - Produces sparse models.
- **L2 Regularization (Ridge)**: Adds `Î» * ||w||â‚‚Â²` to loss.
  - Shrinks all weights.

---

## ğŸ“Š Visual Analogy (2D Vector [4, 3])
- **L1**: Go 4 units right, 3 up â†’ distance = 7
- **L2**: Direct diagonal â†’ distance = 5
- **Lâˆ**: Max of either x or y â†’ distance = 4
![Solving L2 Norm](./images/normcalculation.png)
---

## ğŸ“˜ Summary Table

| Norm | Name         | Formula                      | Application          |
|------|--------------|------------------------------|----------------------|
| L1   | Manhattan    | \\|x\\|â‚ = Î£|xáµ¢|             | Lasso, Sparse Models|
| L2   | Euclidean    | \\|x\\|â‚‚ = sqrt(Î£xáµ¢Â²)        | Ridge, General ML   |
| Lâˆ   | Max Norm     | \\|x\\|âˆ = max(|xáµ¢|)         | Robust Models       |

---


